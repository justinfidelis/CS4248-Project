{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb978f41",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4e4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support,balanced_accuracy_score\n",
    "from gensim.models import Word2Vec,FastText\n",
    "from nltk.tokenize import MWETokenizer,word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup, AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "path = r\"C:\\YZC\\NUS\\Semester 2\\CS4248 Natural Language Processing\\Project\\scicite\"\n",
    "os.chdir(path)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else: device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb153f",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc107df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>citeEnd</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>citeStart</th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "      <th>label_confidence</th>\n",
       "      <th>citingPaperId</th>\n",
       "      <th>citedPaperId</th>\n",
       "      <th>isKeyCitation</th>\n",
       "      <th>id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>excerpt_index</th>\n",
       "      <th>label2</th>\n",
       "      <th>label2_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explicit</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>168.0</td>\n",
       "      <td>However, how frataxin interacts with the Fe-S ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649</td>\n",
       "      <td>894be9b4ea46a5c422e81ef3c241072d4c73fdc0</td>\n",
       "      <td>True</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>explicit</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Novel Quantitative Trait Loci for Seminal Root...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>In the study by Hickey et al. (2012), spikes w...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b</td>\n",
       "      <td>b6642e19efb8db5623b3cc4eef1c5822a6151107</td>\n",
       "      <td>True</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>explicit</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>225.0</td>\n",
       "      <td>The drug also reduces catecholamine secretion,...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc</td>\n",
       "      <td>4e6a17fb8d7a3cada601d942e22eb5da6d01adbd</td>\n",
       "      <td>False</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>explicit</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>46.0</td>\n",
       "      <td>By clustering with lowly aggressive close kin ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b</td>\n",
       "      <td>2cc6ff899bf17666ad35893524a4d61624555ed7</td>\n",
       "      <td>False</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explicit</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Ophthalmic symptoms are rare manifestations of...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175</td>\n",
       "      <td>a5bb0ff1a026944d2a47a155462959af2b8505a8</td>\n",
       "      <td>False</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source  citeEnd                                        sectionName  \\\n",
       "0  explicit    175.0                                       Introduction   \n",
       "1  explicit     36.0  Novel Quantitative Trait Loci for Seminal Root...   \n",
       "2  explicit    228.0                                       Introduction   \n",
       "3  explicit    110.0                                         Discussion   \n",
       "4  explicit    239.0                                         Discussion   \n",
       "\n",
       "   citeStart                                             string       label  \\\n",
       "0      168.0  However, how frataxin interacts with the Fe-S ...  background   \n",
       "1       16.0  In the study by Hickey et al. (2012), spikes w...  background   \n",
       "2      225.0  The drug also reduces catecholamine secretion,...  background   \n",
       "3       46.0  By clustering with lowly aggressive close kin ...  background   \n",
       "4      234.0  Ophthalmic symptoms are rare manifestations of...  background   \n",
       "\n",
       "   label_confidence                             citingPaperId  \\\n",
       "0               1.0  1872080baa7d30ec8fb87be9a65358cd3a7fb649   \n",
       "1               1.0  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b   \n",
       "2               1.0  9cdf605beb1aa1078f235c4332b3024daa8b31dc   \n",
       "3               1.0  d9f3207db0c79a3b154f3875c9760cc6b056904b   \n",
       "4               1.0  88b86556857f4374842d2af2e359576806239175   \n",
       "\n",
       "                               citedPaperId  isKeyCitation  \\\n",
       "0  894be9b4ea46a5c422e81ef3c241072d4c73fdc0           True   \n",
       "1  b6642e19efb8db5623b3cc4eef1c5822a6151107           True   \n",
       "2  4e6a17fb8d7a3cada601d942e22eb5da6d01adbd          False   \n",
       "3  2cc6ff899bf17666ad35893524a4d61624555ed7          False   \n",
       "4  a5bb0ff1a026944d2a47a155462959af2b8505a8          False   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...   \n",
       "1  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...   \n",
       "2  9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...   \n",
       "3  d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...   \n",
       "4  88b86556857f4374842d2af2e359576806239175>a5bb0...   \n",
       "\n",
       "                                           unique_id  excerpt_index label2  \\\n",
       "0  1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...             11    NaN   \n",
       "1  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...              2    NaN   \n",
       "2  9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...              0    NaN   \n",
       "3  d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...              3    NaN   \n",
       "4  88b86556857f4374842d2af2e359576806239175>a5bb0...              2    NaN   \n",
       "\n",
       "   label2_confidence  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('train.jsonl',lines=True)\n",
    "df_test = pd.read_json('test.jsonl',lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6978616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Questions:\n",
    "excerpt_index?\n",
    "citeStart, citeEnd?\n",
    "label2 (supportiveness)?\n",
    "isKeyCitation?\n",
    "'''\n",
    "no_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e3370",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83433209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_test():\n",
    "    null_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any(): null_cols.append(col)\n",
    "    print(null_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de41c53",
   "metadata": {},
   "source": [
    "#### Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f712d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = MWETokenizer([('<','bos','>'),('<','eos','>')],separator='')\n",
    "# tk.add_mwe([('<','bos','>'),('<','eos','>')])\n",
    "\n",
    "def convert_label(value):\n",
    "    if value == 'background':\n",
    "        label = 0\n",
    "    elif value == 'method':\n",
    "        label = 1\n",
    "    elif value == 'result':\n",
    "        label = 2\n",
    "    return label\n",
    "\n",
    "def NA_impute(df):\n",
    "    df['label2'] = df['label2'].fillna('cant_determine')\n",
    "    try:\n",
    "        print(len(df).df.columns)\n",
    "        df = df.drop(columns='label2_confidence',axis=1)\n",
    "        df_type = 'train'\n",
    "    except:\n",
    "        df_type = 'test'\n",
    "    df['label_confidence'] = df['label_confidence'].fillna(df['label_confidence'].mean())\n",
    "    df['citeStart'] = df['citeStart'].fillna(df['citeStart'].mean().astype(np.int64))\n",
    "    df['citeEnd'] = df['citeEnd'].fillna(df['citeEnd'].mean().astype(np.int64))\n",
    "    df['source'] = df['source'].fillna('unknown')\n",
    "    df['sectionName'] = df['sectionName'].fillna('unknown')\n",
    "    return df, df_type\n",
    "\n",
    "def add_sectionName(df):\n",
    "    df['string_lower_sn'] = df.apply(lambda x:x.sectionName.lower()+' '+x.string_lower,axis=1)\n",
    "    df['tokens_lower_sn'] = df['string_lower_sn'].apply(lambda x: tk.tokenize(word_tokenize(x)))\n",
    "    return df\n",
    "\n",
    "def process_df(df):\n",
    "    df, df_type = NA_impute(df)\n",
    "    for col in ['citeStart','citeEnd']:\n",
    "        df[col] = df[col].astype('int64')\n",
    "    feature_cols = ['source', 'citeEnd', 'sectionName', 'citeStart', 'label_confidence', 'citingPaperId', 'citedPaperId', 'isKeyCitation', 'excerpt_index', 'label2', 'label2_confidence']\n",
    "    if df_type == 'test':\n",
    "        feature_cols.remove('label2_confidence')\n",
    "    df['edited_string'] = ''\n",
    "    for col in feature_cols:\n",
    "        df['edited_string'] += col + ': ' + df[col].astype(str) + '[SEP]'\n",
    "    df['edited_string'] += df['string']\n",
    "    df['tagged_string'] = '<BOS>' + df['string'] + '<EOS>'\n",
    "    df['label_num'] = df['label'].apply(lambda x: convert_label(x))\n",
    "    df['string_lower'] = df['tagged_string'].apply(lambda x: x.lower())\n",
    "    df['tokens_lower'] = df['string_lower'].apply(lambda x: tk.tokenize(word_tokenize(x)))  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a28734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = process_df(df)\n",
    "df_test = process_df(df_test)\n",
    "# Remove outliers, i.e. lengthy sentences\n",
    "df_train = df_train.loc[df_train['tokens_lower'].str.len() <= 100]\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38280d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hypotheses:\n",
    "Word embeddings\n",
    "Combine word embeddings with features\n",
    "Attention mechanism\n",
    "Include the sentences immediately before and after\n",
    "Activation functions\n",
    "\n",
    "Open questions\n",
    "- Where can we get more contextual information? How to incorporate?\n",
    "- variables:\n",
    "    - lower case? stopwords? lemmatization? any words to include?\n",
    "'''\n",
    "no_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762ebf8",
   "metadata": {},
   "source": [
    "#### Preparing Embedding Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4319d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input array (batch_first = True): N (batch size) * L (sequence length) * H_in (input size)\n",
    "'''\n",
    "def generate_X(df,token_col,model,seq_len,vec_size):\n",
    "    '''\n",
    "    token_col: col for tokens in dataframe\n",
    "    model: word vectorization model\n",
    "    '''\n",
    "    X = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        i_arr = [model.wv[token] for token in df.at[i,token_col]]\n",
    "        if len(i_arr) < seq_len:\n",
    "            while len(i_arr) < seq_len:\n",
    "                i_arr.append(np.zeros(vec_size))\n",
    "        elif len(i_arr) > seq_len:\n",
    "            i_arr = i_arr[:seq_len]\n",
    "        X.append(i_arr)\n",
    "    return np.array(X)\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].to_numpy()\n",
    "\n",
    "def generate_static_features(df):\n",
    "    num_cols = ['citeStart','citeEnd','excerpt_index','isKeyCitation']\n",
    "    cat_cols = ['label2']\n",
    "    num_pipeline = Pipeline([\n",
    "        ('selector',DataFrameSelector(num_cols)),\n",
    "        ('scaler',StandardScaler())\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('selector',DataFrameSelector(cat_cols)),\n",
    "        ('ohe',OneHotEncoder())\n",
    "    ])\n",
    "    combined_pipeline = FeatureUnion([\n",
    "        ('num',num_pipeline),\n",
    "        ('cat',cat_pipeline)\n",
    "    ])\n",
    "    sf = combined_pipeline.fit_transform(df)\n",
    "    return sf\n",
    "\n",
    "def convert_y(y): # for training and validation labels. For y_val, keep one multi-target and one single-target version\n",
    "    y_nn = np.zeros([y.shape[0],3])\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            y_nn[i,0] = 1\n",
    "        elif y[i] == 1:\n",
    "            y_nn[i,1] = 1\n",
    "        elif y[i] == 2: \n",
    "            y_nn[i,2] = 1\n",
    "    return y_nn\n",
    "\n",
    "def to_tensor(arr,dtype='Float'):\n",
    "    if dtype == \"Float\":\n",
    "        arr = torch.from_numpy(arr).type(torch.FloatTensor)\n",
    "    elif dtype == \"Long\":\n",
    "        arr = torch.from_numpy(arr).type(torch.LongTensor)\n",
    "    return arr\n",
    "\n",
    "def check_dist_y(y,n=None):\n",
    "    '''\n",
    "    y: torch array\n",
    "    n: last index of sample\n",
    "    '''\n",
    "    if n == None:\n",
    "        print(torch.sum(y_train,dim=0))\n",
    "    else:\n",
    "        print(torch.sum(y_train[:n],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e9188c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 200 # hp\n",
    "seq_length = 100 # max word length based on tokenization, including padding tokens. Outliers removed (~ 1.5% of dataset)\n",
    "corpus = df_train['tokens_lower'].tolist()\n",
    "ft = FastText(corpus,vector_size=vec_size,epochs=10)\n",
    "sf_core = generate_static_features(df_train)\n",
    "sf_test = generate_static_features(df_test)\n",
    "y_core = df_train['label_num'].to_numpy()\n",
    "y_test = df_test['label_num'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1de9a",
   "metadata": {},
   "source": [
    "#####  For Subsequent Runs (with Tensors Saved), Ignore this Cell:\n",
    "*i.e. Only run once*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd156264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155d468e43ce4ed8addf01def94e858b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401409f4c94542bd996b8f0d995dbbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1861 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_core = generate_X(df_train,'tokens_lower',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_test = generate_X(df_test,'tokens_lower',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_train, X_val, sf_train, sf_val, y_train, y_val = train_test_split(X_core,sf_core,y_core,test_size=0.2,random_state= 1)\n",
    "y_train, y_val_nn = convert_y(y_train),convert_y(y_val)\n",
    "X_train, X_val, X_test, sf_train, sf_val, sf_test = to_tensor(X_train), to_tensor(X_val), to_tensor(X_test), to_tensor(sf_train.toarray()), to_tensor(sf_val.toarray()), to_tensor(sf_test.toarray()),\n",
    "y_train, y_val_nn = to_tensor(y_train), to_tensor(y_val_nn)\n",
    "torch.save([X_train,X_val,X_test,sf_train,sf_val,sf_test,y_train,y_val_nn],'data_arrays_v0.pt') # embeddings only\n",
    "np.savez('y_arr_v0.npz',y_val=y_val,y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8846f0",
   "metadata": {},
   "source": [
    "##### For Subsequent Runs (Tensors Saved), Resume from this Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc06333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train,X_val,X_test,sf_train,sf_val,sf_test,y_train,y_val_nn = torch.load('data_arrays_v0.pt')\n",
    "data = np.load('y_arr_v0.npz')\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "\n",
    "# Utility/Essential parameters\n",
    "vec_size = 200 # hp\n",
    "seq_length = 100 # max word length based on tokenization, including padding tokens\n",
    "models_generated = ['rnn_0','rnn_a','rnn_a_sf','rnn_a_sf1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9262e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dist(arr):\n",
    "    unique, counts = np.unique(arr,return_counts=True)\n",
    "    return list(zip(unique,counts))\n",
    "    \n",
    "def resample_arr(X,y,rng): # Not used\n",
    "    y_0 = y[:,0] == 1 # class 0\n",
    "    y_non0 =  y[:,0] == 0 # class 1 or 2\n",
    "    idx_0 = y_0.nonzero().numpy() # list of lists (numpy)\n",
    "    idx_non0 = y_non0.nonzero() # list of lists (torch)\n",
    "    idx_sample_0 = rng.choice(idx_0,len(idx_0)//3) # as size of class 0 ~ 4x that of other classes\n",
    "    idx_sample_0 = torch.from_numpy(idx_sample_0).type(torch.LongTensor)\n",
    "    idx_sample = torch.cat((idx_sample_0.squeeze(1),idx_non0.squeeze(1))) \n",
    "    del y_0,y_non0,idx_0,idx_non0,idx_sample_0\n",
    "    return X[idx_sample], y[idx_sample]\n",
    "\n",
    "def train_and_save(model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs):\n",
    "    '''\n",
    "    sf: [bool] whether static features are included or not\n",
    "    '''\n",
    "    X_val, sf_val = kwargs.get('X_val', None),kwargs.get('sf_val', None)\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "        # Data resampling to offset class imbalance\n",
    "#         X_sample, y_sample = resample_arr(X_train,y_train,rng)\n",
    "#         check_dist(y_sample.numpy()[:,0]);check_dist(y_sample.numpy()[:,1]); check_dist(y_sample.numpy()[:,2]) # Troubleshooting\n",
    "#         loader = DataLoader(TensorDataset(X_sample.to(device),y_sample.to(device)),batch_size=batch_size)\n",
    "\n",
    "        if sf == False:\n",
    "            for X_batch, y_batch in loader:\n",
    "                y_pred_batch = model(X_batch)\n",
    "                loss = loss_fn(y_pred_batch,y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        else:\n",
    "            for X_batch, sf_batch, y_batch in loader:\n",
    "                y_pred_batch = model(X_batch,sf_batch)\n",
    "                loss = loss_fn(y_pred_batch,y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if sf == False:\n",
    "                y_pred_nn = model(X_val)\n",
    "            else:\n",
    "                y_pred_nn = model(X_val,sf_val)\n",
    "            y_pred = torch.argmax(y_pred_nn,1).detach().cpu()\n",
    "            y_dist = check_dist(y_pred) # Troubleshooting \n",
    "            print(y_dist) # Troubleshooting\n",
    "            bal_accuracy = balanced_accuracy_score(y_val,y_pred)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                precision, recall, fscore, support = precision_recall_fscore_support(y_val,y_pred,average='weighted')\n",
    "            val_loss = loss_fn(y_pred_nn,y_val_nn)\n",
    "            tqdm.write(f\"Epoch{epoch+1}: val loss={val_loss}, balanced accuracy={bal_accuracy}, precision={precision}, recall={recall}, fscore={fscore}\")\n",
    "            \n",
    "            # Early Stopping\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_epoch = epoch + 1\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                patience = 10\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f'Early stopping triggered at epoch {epoch+1}. Best model is from epoch {best_epoch}.')\n",
    "                    break\n",
    "        \n",
    "        # For memory saving\n",
    "        try:\n",
    "            del X_sample,y_sample\n",
    "            gc.collect()\n",
    "        except:\n",
    "            True\n",
    "    torch.save(best_model_weights,filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737358e0",
   "metadata": {},
   "source": [
    "#### Naive RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abc540fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "class RNN_base(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN_base,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n",
    "        self.ff = nn.Linear(hidden_size,output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(1,x.size(0),self.hidden_size).to(device)\n",
    "        # 1: number of RNN layers. x.size(0): batch_size.\n",
    "        _, hidden = self.rnn(x,h0)\n",
    "        output = self.ff(hidden[-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aa8dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5898660095487448 0.2782997073771754 0.13183428307407977\n"
     ]
    }
   ],
   "source": [
    "# For reference\n",
    "class0 = check_dist(y_train[:,0])[1][1]\n",
    "class1 = check_dist(y_train[:,1])[1][1]\n",
    "class2 = check_dist(y_train[:,2])[1][1]\n",
    "print(class0/len(y_train),class1/len(y_train),class2/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60aa9834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e9e8e3701f428bb37d3130467b9876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1623), (1, 1)]\n",
      "Epoch1: val loss=0.9455477595329285, balanced accuracy=0.33408919123204833, precision=0.6154019801559479, recall=0.5868226600985221, fscore=0.434680364535915\n",
      "[(0, 1623), (1, 1)]\n",
      "Epoch2: val loss=0.9733210206031799, balanced accuracy=0.33408919123204833, precision=0.6154019801559479, recall=0.5868226600985221, fscore=0.434680364535915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     37\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(TensorDataset(X_train\u001b[38;5;241m.\u001b[39mto(device),y_train\u001b[38;5;241m.\u001b[39mto(device)),batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m---> 38\u001b[0m rnn0 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn0\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRNN_v0.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 31\u001b[0m, in \u001b[0;36mtrain_and_save\u001b[1;34m(model, filename, loss_fn, optimizer, loader, X_val, y_val_nn, y_val, n_epochs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng()\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# Data resampling to offset class imbalance\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#         X_sample, y_sample = resample_arr(X_train,y_train,rng)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#         check_dist(y_sample.numpy()[:,0]);check_dist(y_sample.numpy()[:,1]); check_dist(y_sample.numpy()[:,2]) # Troubleshooting\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#         loader = DataLoader(TensorDataset(X_sample.to(device),y_sample.to(device)),batch_size=batch_size)\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_pred_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "hidden_size = 150\n",
    "batch_size = 2\n",
    "lr = 0.0004\n",
    "\n",
    "# Save memory\n",
    "for var in models_generated:\n",
    "    if var in globals(): del var\n",
    "gc.collect()\n",
    "\n",
    "# # Build and train\n",
    "# Building Approach 1: Using Module\n",
    "rnn0 = RNN_base(input_size=vec_size,hidden_size=hidden_size,output_size=y_train.shape[1]).to(device)\n",
    "\n",
    "# # Building Apprach 2: Using Sequential -> WIP: to enable weight analysis\n",
    "# class generate_h(nn.Module):\n",
    "#     def __init__(self,hidden_size):\n",
    "#         super(generate_h,self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#     def forward(self,x):\n",
    "#         return torch.zeros(1,x.size(0),self.hidden_size).to(device)\n",
    "# class generate\n",
    "\n",
    "# rnn0 = nn.Sequential(\n",
    "#     generate_h(hidden_size),\n",
    "#     nn.RNN(input_size,hidden_size,batch_first=True),\n",
    "#     nn.Linear(hidden_size,output_size)\n",
    "# )\n",
    "\n",
    "optimizer = optim.Adam(rnn0.parameters(),lr=lr)\n",
    "# Weighted loss required for RNN to not assign all labels to one class\n",
    "weights = torch.tensor([1, 2, 2.5]).to(device) #hp\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "loader = DataLoader(TensorDataset(X_train.to(device),y_train.to(device)),batch_size=batch_size)\n",
    "'''\n",
    "train_and_save args: model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\n",
    "'''\n",
    "rnn0 = train_and_save(rnn0,'RNN_v0.pt',\n",
    "                      loss_fn,optimizer,\n",
    "                      loader,\n",
    "                      X_val.to(device),y_val_nn.to(device),y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfc2af",
   "metadata": {},
   "source": [
    "#### RNN with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "738f1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/mttk/rnn-classifier/blob/master/model.py\n",
    "\n",
    "# Self attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "    \n",
    "    def forward(self,dec_hidden_state,enc_hidden_states):\n",
    "        '''\n",
    "        ('query': hidden from rnn) dec_hidden_states: 1 * batch_size * hidden_size\n",
    "        ('key'/'value': output from rnn) enc_hidden_state: batch_size * seq_len * hidden_size\n",
    "        '''\n",
    "        attn_w = torch.bmm(dec_hidden_state.transpose(0,1),enc_hidden_states.transpose(1,2)) # (B*1*H,B*H*L)\n",
    "        attn_w = torch.nn.functional.softmax(attn_w.squeeze(1),dim=1) # need to standardize with ^. (B*1*L -> B*L)\n",
    "        context = torch.bmm(enc_hidden_states.transpose(1,2),attn_w.unsqueeze(2)).squeeze(2) # (B*H*L,B*L*1)\n",
    "        return torch.cat((context,dec_hidden_state.squeeze(0)),dim=1) # batch_size * (2*hidden_size)\n",
    "        \n",
    "class RNN_Attn(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN_Attn,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n",
    "        self.attn = Attention()\n",
    "        self.dec = nn.Linear(2*hidden_size,output_size) # define context_size\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(1,x.size(0),self.hidden_size).to(device) # 1: number of RNN layers. x.size(0): batch_size.\n",
    "        output, hidden = self.rnn(x,h0) # hidden: enc_hidden. output: dec_hidden\n",
    "        c_h = self.attn(hidden,output)\n",
    "        output = self.dec(c_h)\n",
    "#         output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "666b12a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d226c03f68874d47a6f00293dc24f6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 978), (1, 444), (2, 202)]\n",
      "Epoch1: val loss=0.5450728535652161, balanced accuracy=0.7415880493611585, precision=0.7862471267481351, recall=0.7875615763546798, fscore=0.7863688411440127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     16\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(TensorDataset(X_train\u001b[38;5;241m.\u001b[39mto(device),y_train\u001b[38;5;241m.\u001b[39mto(device)),batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m---> 17\u001b[0m rnn_a \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_a\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRNN_Attn_v0.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 35\u001b[0m, in \u001b[0;36mtrain_and_save\u001b[1;34m(model, filename, loss_fn, optimizer, loader, X_val, y_val_nn, y_val, n_epochs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred_batch,y_batch)\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "hidden_size = 70\n",
    "batch_size = 2 # OOM when batch_size >= 4\n",
    "lr = 0.0002\n",
    "\n",
    "# Save memory\n",
    "for var in models_generated:\n",
    "    if var in globals(): del var\n",
    "gc.collect()\n",
    "\n",
    "# Build and train\n",
    "rnn_a = RNN_Attn(input_size=vec_size,hidden_size=hidden_size,output_size=y_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(rnn_a.parameters(),lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = DataLoader(TensorDataset(X_train.to(device),y_train.to(device)),batch_size=batch_size)\n",
    "'''\n",
    "train_and_save args: model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\n",
    "'''\n",
    "rnn_a = train_and_save(rnn_a,'RNN_Attn_v0.pt',\n",
    "                     loss_fn,optimizer,\n",
    "                     loader,X_val.to(device),y_val_nn.to(device),y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(Reference) Getting model weights: \n",
    "https://stackoverflow.com/questions/44130851/simple-lstm-in-pytorch-with-sequential-module\n",
    "https://discuss.pytorch.org/t/how-to-get-all-weights-of-rnn-in-pytorch/33794/2\n",
    "'''\n",
    "no_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee8ae2",
   "metadata": {},
   "source": [
    "#### RNN_Attn with Static Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b3267",
   "metadata": {},
   "source": [
    "Build and Train Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45288041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Attn_StatFeat(nn.Module):\n",
    "    def __init__(self,input_size,feat_size,hidden_size,hidden_size2,output_size):\n",
    "        super(RNN_Attn_StatFeat,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n",
    "        self.attn = Attention()\n",
    "        self.dec = nn.Linear(2*hidden_size,hidden_size2) # define context_size\n",
    "        self.ff1 = nn.Linear(hidden_size2+feat_size,output_size) # combined layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x,sf): # x: embeddings. sf: static features\n",
    "        h0 = torch.zeros(1,x.size(0),self.hidden_size).to(device) # 1: number of RNN layers. x.size(0): batch_size.\n",
    "        output, hidden = self.rnn(x,h0) # hidden: enc_hidden. output: dec_hidden\n",
    "        context_h = self.attn(hidden,output)\n",
    "        context_h2 = self.dec(context_h)\n",
    "        output = self.ff1(torch.cat((context_h2,sf),dim=1))\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5962da8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e651f3d78e404c9a9037cccfa7219610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1617), (1, 7)]\n",
      "Epoch1: val loss=0.946342945098877, balanced accuracy=0.3333333333333333, precision=0.3451261382295865, recall=0.5862068965517241, fscore=0.4344639669266185\n",
      "[(0, 1440), (1, 183), (2, 1)]\n",
      "Epoch2: val loss=0.9002696871757507, balanced accuracy=0.42468654128317995, precision=0.577262342189561, recall=0.6483990147783252, fscore=0.5685871006804291\n",
      "[(0, 1329), (1, 294), (2, 1)]\n",
      "Epoch3: val loss=0.8863833546638489, balanced accuracy=0.4574329731892757, precision=0.5705987501250988, recall=0.6631773399014779, fscore=0.5981036318441268\n",
      "[(0, 1151), (1, 297), (2, 176)]\n",
      "Epoch4: val loss=0.8215010166168213, balanced accuracy=0.6578262618178584, precision=0.7356138425584221, recall=0.7376847290640394, fscore=0.7245454724733096\n",
      "[(0, 1023), (1, 428), (2, 173)]\n",
      "Epoch5: val loss=0.7423332333564758, balanced accuracy=0.7528385091410302, precision=0.8094902690683033, recall=0.8084975369458128, fscore=0.8060462515042427\n",
      "[(0, 948), (1, 494), (2, 182)]\n",
      "Epoch6: val loss=0.7397065162658691, balanced accuracy=0.7704056370022757, precision=0.8136599883265898, recall=0.8078817733990148, fscore=0.8085763115114083\n",
      "[(0, 989), (1, 436), (2, 199)]\n",
      "Epoch7: val loss=0.725704550743103, balanced accuracy=0.7861321296195246, precision=0.8235996493530181, recall=0.8238916256157636, fscore=0.8229276592690542\n",
      "[(0, 955), (1, 486), (2, 183)]\n",
      "Epoch8: val loss=0.7290248870849609, balanced accuracy=0.7859517544391496, precision=0.8270457493384933, recall=0.8220443349753694, fscore=0.8225387999027199\n",
      "[(0, 1022), (1, 411), (2, 191)]\n",
      "Epoch9: val loss=0.7191099524497986, balanced accuracy=0.7866692131398013, precision=0.8299034009631301, recall=0.8300492610837439, fscore=0.8280373794426952\n",
      "[(0, 993), (1, 449), (2, 182)]\n",
      "Epoch10: val loss=0.7180708646774292, balanced accuracy=0.7935371118144228, precision=0.8358558229272102, recall=0.833128078817734, fscore=0.8325854504617862\n",
      "[(0, 980), (1, 453), (2, 191)]\n",
      "Epoch11: val loss=0.7165752649307251, balanced accuracy=0.8063538546731824, precision=0.8398826859223619, recall=0.8374384236453202, fscore=0.8374340466051299\n",
      "[(0, 939), (1, 511), (2, 174)]\n",
      "Epoch12: val loss=0.7214718461036682, balanced accuracy=0.8003130545147353, precision=0.8428769220931013, recall=0.833743842364532, fscore=0.8348405064303703\n",
      "[(0, 932), (1, 520), (2, 172)]\n",
      "Epoch13: val loss=0.7221619486808777, balanced accuracy=0.8018672115310771, precision=0.84429773996383, recall=0.833128078817734, fscore=0.8347083899160116\n",
      "[(0, 984), (1, 453), (2, 187)]\n",
      "Epoch14: val loss=0.7081751823425293, balanced accuracy=0.8063801278086992, precision=0.8427057030265639, recall=0.8399014778325123, fscore=0.8397913363819272\n",
      "[(0, 995), (1, 437), (2, 192)]\n",
      "Epoch15: val loss=0.7075334787368774, balanced accuracy=0.8096491121701206, precision=0.843349312475143, recall=0.8417487684729064, fscore=0.8412553788930869\n",
      "[(0, 973), (1, 457), (2, 194)]\n",
      "Epoch16: val loss=0.7091169357299805, balanced accuracy=0.8150937142533782, precision=0.8456371554007678, recall=0.8429802955665024, fscore=0.8432566696484711\n",
      "[(0, 942), (1, 496), (2, 186)]\n",
      "Epoch17: val loss=0.7136688828468323, balanced accuracy=0.8100149150569319, precision=0.8429030088279261, recall=0.8355911330049262, fscore=0.8371166933588462\n",
      "[(0, 963), (1, 470), (2, 191)]\n",
      "Epoch18: val loss=0.709786593914032, balanced accuracy=0.8179337391522266, precision=0.8472220952281504, recall=0.8429802955665024, fscore=0.843768156109281\n",
      "[(0, 967), (1, 463), (2, 194)]\n",
      "Epoch19: val loss=0.7077248692512512, balanced accuracy=0.8203584464088666, precision=0.8481631379767319, recall=0.8448275862068966, fscore=0.8454055178401321\n",
      "[(0, 962), (1, 467), (2, 195)]\n",
      "Epoch20: val loss=0.7091841697692871, balanced accuracy=0.8178518882300395, precision=0.8447728863312559, recall=0.8411330049261084, fscore=0.8418910581249581\n",
      "[(0, 967), (1, 467), (2, 190)]\n",
      "Epoch21: val loss=0.7064264416694641, balanced accuracy=0.8186471558320297, precision=0.8493594974187919, recall=0.8454433497536946, fscore=0.8460344402072825\n",
      "[(0, 952), (1, 463), (2, 209)]\n",
      "Epoch22: val loss=0.7099359631538391, balanced accuracy=0.8203614779245031, precision=0.8414000434541332, recall=0.8392857142857143, fscore=0.8399180979990409\n",
      "[(0, 983), (1, 443), (2, 198)]\n",
      "Epoch23: val loss=0.7022691369056702, balanced accuracy=0.8207677010198019, precision=0.8492637631304794, recall=0.8479064039408867, fscore=0.8477248916756677\n",
      "[(0, 980), (1, 429), (2, 215)]\n",
      "Epoch24: val loss=0.7038100361824036, balanced accuracy=0.8237289865441126, precision=0.8466562221144647, recall=0.8472906403940886, fscore=0.8466689386646004\n",
      "[(0, 984), (1, 446), (2, 194)]\n",
      "Epoch25: val loss=0.703636109828949, balanced accuracy=0.8139452750797288, precision=0.8453538495866724, recall=0.8435960591133005, fscore=0.8434073502428391\n",
      "[(0, 981), (1, 447), (2, 196)]\n",
      "Epoch26: val loss=0.7006700038909912, balanced accuracy=0.8223349946039021, precision=0.8504187158176045, recall=0.8485221674876847, fscore=0.8485153648855035\n",
      "[(0, 975), (1, 449), (2, 200)]\n",
      "Epoch27: val loss=0.7032047510147095, balanced accuracy=0.8219717179801213, precision=0.8482583644467812, recall=0.8466748768472906, fscore=0.8467412118426172\n",
      "[(0, 983), (1, 443), (2, 198)]\n",
      "Epoch28: val loss=0.6984923481941223, balanced accuracy=0.8262158398713021, precision=0.8537155461638228, recall=0.8522167487684729, fscore=0.8520975882590819\n",
      "[(0, 1026), (1, 380), (2, 218)]\n",
      "Epoch29: val loss=0.6968145370483398, balanced accuracy=0.819888056232594, precision=0.8485338182885594, recall=0.8497536945812808, fscore=0.8471742309103825\n",
      "[(0, 991), (1, 429), (2, 204)]\n",
      "Epoch30: val loss=0.7025163769721985, balanced accuracy=0.8157449848626319, precision=0.8425192870460163, recall=0.8423645320197044, fscore=0.8417249365538538\n",
      "[(0, 1015), (1, 408), (2, 201)]\n",
      "Epoch31: val loss=0.7092645764350891, balanced accuracy=0.8025422290128171, precision=0.8362922857174175, recall=0.8368226600985221, fscore=0.8351441897894328\n",
      "[(0, 1069), (1, 360), (2, 195)]\n",
      "Epoch32: val loss=0.7080181241035461, balanced accuracy=0.7895688578461687, precision=0.836110970675884, recall=0.8349753694581281, fscore=0.8309136062438578\n",
      "[(0, 1052), (1, 374), (2, 198)]\n",
      "Epoch33: val loss=0.7048251032829285, balanced accuracy=0.8015251555167522, precision=0.8438969253148176, recall=0.8435960591133005, fscore=0.8403617769749266\n",
      "[(0, 1011), (1, 419), (2, 194)]\n",
      "Epoch34: val loss=0.7015004754066467, balanced accuracy=0.8137133641335321, precision=0.848661326385287, recall=0.8479064039408867, fscore=0.846749496505196\n",
      "[(0, 1017), (1, 418), (2, 189)]\n",
      "Epoch35: val loss=0.7012688517570496, balanced accuracy=0.8089230641751649, precision=0.8479014283635407, recall=0.8466748768472906, fscore=0.8453502492889778\n",
      "[(0, 963), (1, 469), (2, 192)]\n",
      "Epoch36: val loss=0.7200007438659668, balanced accuracy=0.8028554856285949, precision=0.8302895491640919, recall=0.8257389162561576, fscore=0.8267650077992033\n",
      "[(0, 1075), (1, 352), (2, 197)]\n",
      "Epoch37: val loss=0.7093313932418823, balanced accuracy=0.7944869867138774, precision=0.8409530802513943, recall=0.8392857142857143, fscore=0.8349173885690213\n",
      "[(0, 1433), (1, 22), (2, 169)]\n",
      "Epoch38: val loss=0.8504262566566467, balanced accuracy=0.5889997413106657, precision=0.7402905811732844, recall=0.6988916256157636, fscore=0.6066427555346645\n",
      "[(0, 1352), (1, 105), (2, 167)]\n",
      "Epoch39: val loss=0.8302481174468994, balanced accuracy=0.6229638319974454, precision=0.7416089775152815, recall=0.7222906403940886, fscore=0.6679992325501661\n",
      "Early stopping triggered at epoch 39. Best model is from epoch 29.\n"
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "hidden_size = 70\n",
    "hidden_size2 = 50\n",
    "batch_size = 2 # OOM when batch_size >= 4\n",
    "feat_size = sf_train.shape[1]\n",
    "lr = 0.0002\n",
    "\n",
    "# Save memory\n",
    "for var in models_generated:\n",
    "    if var in globals(): del var\n",
    "gc.collect()\n",
    "\n",
    "# Build and train\n",
    "'''\n",
    "RNN_Attn_StatFeat args: input_size,feat_size,hidden_size,hidden_size2,output_size\n",
    "'''\n",
    "rnn_a_sf = RNN_Attn_StatFeat(input_size=vec_size,feat_size=feat_size,\n",
    "                             hidden_size=hidden_size,hidden_size2=hidden_size2,\n",
    "                             output_size=y_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(rnn_a_sf.parameters(),lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = DataLoader(TensorDataset(X_train.to(device),sf_train.to(device),y_train.to(device)),batch_size=batch_size)\n",
    "'''\n",
    "train_and_save args: model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\n",
    "'''\n",
    "rnn_a_sf = train_and_save(rnn_a_sf,'RNN_Attn_sf.pt',\n",
    "                     loss_fn,optimizer,\n",
    "                     loader,y_val_nn.to(device),y_val,sf=True,X_val=X_val.to(device),sf_val=sf_val.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe56797",
   "metadata": {},
   "source": [
    "#### RNN_Attn_StatFeat with Section Header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68c084",
   "metadata": {},
   "source": [
    "##### For Subsequent Runs (Tensors Saved), Ignore this Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ee0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic inclusion\n",
    "df_train, df_test = add_sectionName(df_train), add_sectionName(df_test)\n",
    "df_train = df_train.loc[df_train['tokens_lower'].str.len() <= 100]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "corpus_sn = df_train['tokens_lower_sn'].tolist()\n",
    "ft_sn = FastText(corpus_sn,vector_size=vec_size,epochs=10)\n",
    "# unchanged: sf_core, y_core. Note:\n",
    "    # sf_core is not a tensor (sf_train and sf_val definitely are, but not sf_train_sn and sf_val_sn)\n",
    "    # sf_test and y_test no change, as no changes to features and not implicated by the repeat of train-val splits\n",
    "X_core_sn = generate_X(df_train,'tokens_lower_sn',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_test_sn = generate_X(df_test,'tokens_lower_sn',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_train_sn, X_val_sn, sf_train_sn, sf_val_sn, y_train_sn, y_val_sn = train_test_split(X_core_sn,sf_core,y_core,test_size=0.2,random_state= 1)\n",
    "y_train_sn, y_val_sn_nn = convert_y(y_train_sn),convert_y(y_val_sn)\n",
    "if torch.is_tensor(sf_test):\n",
    "    X_train_sn, X_val_sn, X_test_sn, sf_train_sn, sf_val_sn = to_tensor(X_train_sn), to_tensor(X_val_sn), to_tensor(X_test_sn), to_tensor(sf_train_sn.toarray()), to_tensor(sf_val_sn.toarray())\n",
    "else:\n",
    "    X_train_sn, X_val_sn, X_test_sn, sf_train_sn, sf_val_sn, sf_test = to_tensor(X_train_sn), to_tensor(X_val_sn), to_tensor(X_test_sn), to_tensor(sf_train_sn.toarray()), to_tensor(sf_val_sn.toarray()), to_tensor(sf_test.toarray())\n",
    "y_train_sn, y_val_sn_nn = to_tensor(y_train_sn), to_tensor(y_val_sn_nn)\n",
    "torch.save([X_train_sn,X_val_sn,X_test_sn,sf_train_sn,sf_val_sn,sf_test,y_train_sn,y_val_sn_nn],'data_arrays_sn_v0.pt') # embeddings only\n",
    "np.savez('y_arr_sn_v0.npz',y_val=y_val_sn,y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70462d4",
   "metadata": {},
   "source": [
    "##### For Subsequent Runs (Tensors Saved), Resume from this Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc76c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sn,X_val_sn,X_test_sn,sf_train_sn,sf_val_sn,sf_test,y_train_sn,y_val_sn_nn = torch.load('data_arrays_sn_v0.pt')\n",
    "data_sn = np.load('y_arr_sn_v0.npz')\n",
    "y_val_sn = data_sn['y_val']\n",
    "y_test = data_sn['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e01f138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cf7b1309a04ad09426937644fd116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1285), (1, 338), (2, 1)]\n",
      "Epoch1: val loss=0.8915425539016724, balanced accuracy=0.4710606464808145, precision=0.572199819063369, recall=0.6650246305418719, fscore=0.6056641833643287\n",
      "[(0, 1249), (1, 374), (2, 1)]\n",
      "Epoch2: val loss=0.8438905477523804, balanced accuracy=0.514917077942288, precision=0.6095374455566667, recall=0.7050492610837439, fscore=0.6474837485163338\n",
      "[(0, 1266), (1, 357), (2, 1)]\n",
      "Epoch3: val loss=0.8287297487258911, balanced accuracy=0.5219198790627363, precision=0.6230685361250237, recall=0.7173645320197044, fscore=0.6585172217412721\n",
      "[(0, 1082), (1, 392), (2, 150)]\n",
      "Epoch4: val loss=0.7485403418540955, balanced accuracy=0.7343482847684527, precision=0.8131044612694973, recall=0.8078817733990148, fscore=0.8028704986792734\n",
      "[(0, 995), (1, 467), (2, 162)]\n",
      "Epoch5: val loss=0.719699501991272, balanced accuracy=0.7801868222036289, precision=0.8365693028220017, recall=0.8318965517241379, fscore=0.8303569263537796\n",
      "[(0, 953), (1, 500), (2, 171)]\n",
      "Epoch6: val loss=0.7110909819602966, balanced accuracy=0.7989357359105259, precision=0.8457823211192218, recall=0.8392857142857143, fscore=0.8391596464997819\n",
      "[(0, 945), (1, 492), (2, 187)]\n",
      "Epoch7: val loss=0.7065936923027039, balanced accuracy=0.8177210278050614, precision=0.8541814398874211, recall=0.8497536945812808, fscore=0.8500304411194158\n",
      "[(0, 951), (1, 473), (2, 200)]\n",
      "Epoch8: val loss=0.6979054808616638, balanced accuracy=0.8304038787232065, precision=0.8583381427441921, recall=0.8559113300492611, fscore=0.8562440133993087\n",
      "[(0, 958), (1, 454), (2, 212)]\n",
      "Epoch9: val loss=0.6934708952903748, balanced accuracy=0.8420494460410427, precision=0.8622716069582824, recall=0.8614532019704434, fscore=0.8615876054428218\n",
      "[(0, 963), (1, 442), (2, 219)]\n",
      "Epoch10: val loss=0.6906293034553528, balanced accuracy=0.8386890109579186, precision=0.8594605004749667, recall=0.8596059113300493, fscore=0.8594311376523016\n",
      "[(0, 969), (1, 441), (2, 214)]\n",
      "Epoch11: val loss=0.6875832080841064, balanced accuracy=0.8436889907478143, precision=0.8657181646510733, recall=0.8657635467980296, fscore=0.8655231559421642\n",
      "[(0, 983), (1, 430), (2, 211)]\n",
      "Epoch12: val loss=0.6820006370544434, balanced accuracy=0.8419549638037034, precision=0.8666997628160816, recall=0.8669950738916257, fscore=0.8664279118642462\n",
      "[(0, 991), (1, 429), (2, 204)]\n",
      "Epoch13: val loss=0.6807538866996765, balanced accuracy=0.8404695211417902, precision=0.8683813609317715, recall=0.8682266009852216, fscore=0.8675772445738016\n",
      "[(0, 983), (1, 436), (2, 205)]\n",
      "Epoch14: val loss=0.6795390844345093, balanced accuracy=0.8420923925125606, precision=0.8684820364476045, recall=0.8682266009852216, fscore=0.8677767107526436\n",
      "[(0, 995), (1, 416), (2, 213)]\n",
      "Epoch15: val loss=0.6765404939651489, balanced accuracy=0.8533716516909795, precision=0.8771292890661417, recall=0.8774630541871922, fscore=0.8766434994770317\n",
      "[(0, 995), (1, 428), (2, 201)]\n",
      "Epoch16: val loss=0.6785837411880493, balanced accuracy=0.8415330778776157, precision=0.8716454927970041, recall=0.8713054187192119, fscore=0.8705749488799319\n",
      "[(0, 1041), (1, 361), (2, 222)]\n",
      "Epoch17: val loss=0.6835891008377075, balanced accuracy=0.836484593837535, precision=0.8666787803383071, recall=0.8657635467980296, fscore=0.862978539385517\n",
      "[(0, 1002), (1, 420), (2, 202)]\n",
      "Epoch18: val loss=0.6737870573997498, balanced accuracy=0.8478942081883258, precision=0.8766720144552138, recall=0.8762315270935961, fscore=0.8754107641573726\n",
      "[(0, 993), (1, 426), (2, 205)]\n",
      "Epoch19: val loss=0.6709601879119873, balanced accuracy=0.8571084999656429, precision=0.8827055194413584, recall=0.8823891625615764, fscore=0.881794271281606\n",
      "[(0, 1029), (1, 389), (2, 206)]\n",
      "Epoch20: val loss=0.6721136569976807, balanced accuracy=0.8468933027756558, precision=0.879396686133398, recall=0.8786945812807881, fscore=0.876962560776732\n",
      "[(0, 1016), (1, 405), (2, 203)]\n",
      "Epoch21: val loss=0.6721459031105042, balanced accuracy=0.848090751452096, precision=0.8804269227048166, recall=0.8799261083743842, fscore=0.8786908429458707\n",
      "[(0, 1024), (1, 398), (2, 202)]\n",
      "Epoch22: val loss=0.6703027486801147, balanced accuracy=0.8481923072259206, precision=0.8813425051249548, recall=0.8805418719211823, fscore=0.8790861741470749\n",
      "[(0, 997), (1, 430), (2, 197)]\n",
      "Epoch23: val loss=0.6770756244659424, balanced accuracy=0.8451880752300921, precision=0.8754038815039511, recall=0.874384236453202, fscore=0.8737874633033846\n",
      "[(0, 1037), (1, 381), (2, 206)]\n",
      "Epoch24: val loss=0.6744133830070496, balanced accuracy=0.8438698711807956, precision=0.8775241608909897, recall=0.8762315270935961, fscore=0.8743218584960699\n",
      "[(0, 1046), (1, 372), (2, 206)]\n",
      "Epoch25: val loss=0.6714521050453186, balanced accuracy=0.8484085553413285, precision=0.8850064741937406, recall=0.8830049261083743, fscore=0.8808034995850247\n",
      "[(0, 1031), (1, 390), (2, 203)]\n",
      "Epoch26: val loss=0.6687561273574829, balanced accuracy=0.8488238729835368, precision=0.8824253380976532, recall=0.8811576354679803, fscore=0.879580416187504\n",
      "[(0, 1037), (1, 386), (2, 201)]\n",
      "Epoch27: val loss=0.6703365445137024, balanced accuracy=0.8454209966815008, precision=0.8825603343685419, recall=0.8811576354679803, fscore=0.8792945194263316\n",
      "[(0, 1049), (1, 371), (2, 204)]\n",
      "Epoch28: val loss=0.6725728511810303, balanced accuracy=0.8407615571481117, precision=0.879550045448043, recall=0.8774630541871922, fscore=0.8751305381791862\n",
      "[(0, 1058), (1, 337), (2, 229)]\n",
      "Epoch29: val loss=0.6841093897819519, balanced accuracy=0.8283667002154397, precision=0.8654857307123593, recall=0.8626847290640394, fscore=0.8587798906919558\n",
      "[(0, 983), (1, 426), (2, 215)]\n",
      "Epoch30: val loss=0.6718488931655884, balanced accuracy=0.8571115314812793, precision=0.8765563294336163, recall=0.8768472906403941, fscore=0.876337724031105\n",
      "[(0, 1454), (2, 170)]\n",
      "Epoch31: val loss=0.8633573055267334, balanced accuracy=0.5786435786435786, precision=0.5260577242327942, recall=0.6908866995073891, fscore=0.5845013902026543\n",
      "[(0, 1454), (2, 170)]\n",
      "Epoch32: val loss=0.8642961382865906, balanced accuracy=0.5786435786435786, precision=0.5260577242327942, recall=0.6908866995073891, fscore=0.5845013902026543\n",
      "[(0, 1454), (2, 170)]\n",
      "Epoch33: val loss=0.858373761177063, balanced accuracy=0.5786435786435786, precision=0.5260577242327942, recall=0.6908866995073891, fscore=0.5845013902026543\n",
      "[(0, 1448), (1, 7), (2, 169)]\n",
      "Epoch34: val loss=0.8540451526641846, balanced accuracy=0.5784177307286551, precision=0.6428129167460468, recall=0.6902709359605911, fscore=0.5874227729885058\n",
      "[(0, 1452), (1, 2), (2, 170)]\n",
      "Epoch35: val loss=0.8554095029830933, balanced accuracy=0.5790492964862712, precision=0.6619585351952123, recall=0.6908866995073891, fscore=0.5856256026377092\n",
      "[(0, 1338), (1, 115), (2, 171)]\n",
      "Epoch36: val loss=0.8213953375816345, balanced accuracy=0.6352995743752047, precision=0.7525450780628096, recall=0.728448275862069, fscore=0.6793708966598608\n",
      "Early stopping triggered at epoch 36. Best model is from epoch 26.\n"
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "hidden_size = 70\n",
    "hidden_size2 = 50\n",
    "batch_size = 2 # OOM when batch_size >= 4\n",
    "feat_size = sf_train_sn.shape[1]\n",
    "lr = 0.0002\n",
    "\n",
    "# Save memory\n",
    "for var in models_generated:\n",
    "    if var in globals(): del var\n",
    "gc.collect()\n",
    "\n",
    "# Build and train\n",
    "'''\n",
    "RNN_Attn_StatFeat args: input_size,feat_size,hidden_size,hidden_size2,output_size\n",
    "'''\n",
    "rnn_a_sf1 = RNN_Attn_StatFeat(input_size=vec_size,feat_size=feat_size,\n",
    "                             hidden_size=hidden_size,hidden_size2=hidden_size2,\n",
    "                             output_size=y_train_sn.shape[1]).to(device)\n",
    "optimizer = optim.Adam(rnn_a_sf1.parameters(),lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = DataLoader(TensorDataset(X_train_sn.to(device),sf_train_sn.to(device),y_train_sn.to(device)),batch_size=batch_size)\n",
    "'''\n",
    "train_and_save args: model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\n",
    "'''\n",
    "rnn_a_sf1 = train_and_save(rnn_a_sf1,'RNN_Attn_sf_v1.pt',\n",
    "                     loss_fn,optimizer,\n",
    "                     loader,y_val_sn_nn.to(device),y_val_sn,sf=True,X_val=X_val_sn.to(device),sf_val=sf_val_sn.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204dfcbe",
   "metadata": {},
   "source": [
    "#### Word Order\n",
    "Based on RNN_Attn_StatFeat with sectionName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07851a3",
   "metadata": {},
   "source": [
    "##### For Subsequent Runs (Tensors Saved), Ignore this Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcf86f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8d27b200354ecebc7ca9df0df766fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aaafc33aac44ffad0b7e6dc8abedfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1861 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generic inclusion\n",
    "def randomize_tokens(tk_list,rng):\n",
    "    '''\n",
    "    Based on tokens with sectionName\n",
    "    Keep positions of: sectionName bos, eos\n",
    "    '''\n",
    "    target_list = tk_list[2:-1]\n",
    "    reordered_list = tk_list[:2] + rng.permutation(target_list).tolist() + [tk_list[-1]]\n",
    "    return reordered_list\n",
    "\n",
    "def generate_reordered_tokens(df):\n",
    "    rng1 = np.random.default_rng()\n",
    "    df['tokens_lower_sn_jumbled'] = df['tokens_lower_sn'].apply(lambda x:randomize_tokens(x,rng1))\n",
    "    return df\n",
    "\n",
    "# Regenerate col again (in case the cell above hasn't been run)\n",
    "df_train, df_test = add_sectionName(df_train), add_sectionName(df_test)\n",
    "df_train = df_train.loc[df_train['tokens_lower'].str.len() <= 100]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train, df_test = generate_reordered_tokens(df_train), generate_reordered_tokens(df_test)\n",
    "# unchanged: sf_core, y_core. Note:\n",
    "    # sf_core is not a tensor (sf_train and sf_val definitely are, but not sf_train_sn and sf_val_sn)\n",
    "    # y_test has already been loaded\n",
    "    # sf_test and y_test no change, as no changes to features and not implicated by the repeat of train-val splits\n",
    "X_core_sn_ro = generate_X(df_train,'tokens_lower_sn',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_test_sn_ro = generate_X(df_test,'tokens_lower_sn',\n",
    "                   ft,seq_length,vec_size)\n",
    "X_train_sn_ro, X_val_sn_ro, sf_train_sn_ro, sf_val_sn_ro, y_train_sn_ro, y_val_sn_ro = train_test_split(X_core_sn_ro,sf_core,y_core,test_size=0.2,random_state= 1)\n",
    "y_train_sn_ro, y_val_sn_ro_nn = convert_y(y_train_sn_ro),convert_y(y_val_sn_ro)\n",
    "if torch.is_tensor(sf_test): # Depends on whether sf_test has been loaded as or converted to tensor previously\n",
    "    X_train_sn_ro, X_val_sn_ro, X_test_sn_ro, sf_train_sn_ro, sf_val_sn_ro = to_tensor(X_train_sn_ro), to_tensor(X_val_sn_ro), to_tensor(X_test_sn_ro), to_tensor(sf_train_sn_ro.toarray()), to_tensor(sf_val_sn_ro.toarray())\n",
    "else:\n",
    "    X_train_sn_ro, X_val_sn_ro, X_test_sn_ro, sf_train_sn_ro, sf_val_sn_ro, sf_test = to_tensor(X_train_sn_ro), to_tensor(X_val_sn_ro), to_tensor(X_test_sn_ro), to_tensor(sf_train_sn_ro.toarray()), to_tensor(sf_val_sn_ro.toarray()), to_tensor(sf_test.toarray())\n",
    "y_train_sn_ro, y_val_sn_ro_nn = to_tensor(y_train_sn_ro), to_tensor(y_val_sn_ro_nn)\n",
    "torch.save([X_train_sn_ro,X_val_sn_ro,X_test_sn_ro,sf_train_sn_ro,sf_val_sn_ro,sf_test,y_train_sn_ro,y_val_sn_ro_nn],'data_arrays_sn_ro_v0.pt') # embeddings only\n",
    "np.savez('y_arr_sn_ro_v0.npz',y_val=y_val_sn_ro,y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001150e",
   "metadata": {},
   "source": [
    "##### For Subsequent Runs (Tensors Saved), Resume from this Cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d4fb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sn_ro,X_val_sn_ro,X_test_sn_ro,sf_train_sn_ro,sf_val_sn_ro,sf_test,y_train_sn_ro,y_val_sn_ro_nn = torch.load('data_arrays_sn_ro_v0.pt')\n",
    "data_sn = np.load('y_arr_sn_ro_v0.npz')\n",
    "y_val_sn_ro = data_sn['y_val']\n",
    "y_test = data_sn['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d6b47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade3d719d5624ce195d974d36b5d0f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1372), (1, 252)]\n",
      "Epoch1: val loss=0.8767874240875244, balanced accuracy=0.456504824151883, precision=0.5842245149291243, recall=0.6779556650246306, fscore=0.6042967211434183\n",
      "[(0, 1213), (1, 411)]\n",
      "Epoch2: val loss=0.8053643107414246, balanced accuracy=0.5610577564359077, precision=0.6481448146796317, recall=0.7512315270935961, fscore=0.6923192215329085\n",
      "[(0, 1194), (1, 430)]\n",
      "Epoch3: val loss=0.7972503900527954, balanced accuracy=0.5648203725934818, precision=0.6459192346388452, recall=0.75, fscore=0.6917543476055908\n",
      "[(0, 1212), (1, 412)]\n",
      "Epoch4: val loss=0.8002452850341797, balanced accuracy=0.5637866257614157, precision=0.649815005563161, recall=0.7524630541871922, fscore=0.6938534790805186\n",
      "[(0, 1177), (1, 447)]\n",
      "Epoch5: val loss=0.7956586480140686, balanced accuracy=0.5702225334578276, precision=0.6474235604623604, recall=0.7530788177339901, fscore=0.6948112746052932\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 29\u001b[0m\n\u001b[0;32m     22\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(TensorDataset(X_train_sn_ro\u001b[38;5;241m.\u001b[39mto(device),sf_train_sn_ro\u001b[38;5;241m.\u001b[39mto(device),y_train_sn_ro\u001b[38;5;241m.\u001b[39mto(device)),batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mtrain_and_save args: model,filename,\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m                   loss_fn,optimizer,\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m                   loader,\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m rnn_a_sf2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_a_sf2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRNN_Attn_sf_v2.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val_sn_ro_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val_sn_ro\u001b[49m\u001b[43m,\u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val_sn_ro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msf_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf_val_sn_ro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 44\u001b[0m, in \u001b[0;36mtrain_and_save\u001b[1;34m(model, filename, loss_fn, optimizer, loader, y_val_nn, y_val, n_epochs, sf, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, sf_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m---> 44\u001b[0m         y_pred_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43msf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred_batch,y_batch)\n\u001b[0;32m     46\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m, in \u001b[0;36mRNN_Attn_StatFeat.forward\u001b[1;34m(self, x, sf)\u001b[0m\n\u001b[0;32m     12\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# 1: number of RNN layers. x.size(0): batch_size.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(x,h0) \u001b[38;5;66;03m# hidden: enc_hidden. output: dec_hidden\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m context_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m context_h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec(context_h)\n\u001b[0;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff1(torch\u001b[38;5;241m.\u001b[39mcat((context_h2,sf),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, dec_hidden_state, enc_hidden_states)\u001b[0m\n\u001b[0;32m     13\u001b[0m attn_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(dec_hidden_state\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),enc_hidden_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m# (B*1*H,B*H*L)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m attn_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attn_w\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# need to standardize with ^. (B*1*L -> B*L)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_hidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattn_w\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B*H*L,B*L*1)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((context,dec_hidden_state\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "hidden_size = 70\n",
    "hidden_size2 = 50\n",
    "batch_size = 2 # OOM when batch_size >= 4\n",
    "feat_size = sf_train_sn_ro.shape[1]\n",
    "lr = 0.0002\n",
    "\n",
    "# Save memory\n",
    "for var in models_generated:\n",
    "    if var in globals(): del var\n",
    "gc.collect()\n",
    "\n",
    "# Build and train\n",
    "'''\n",
    "RNN_Attn_StatFeat args: input_size,feat_size,hidden_size,hidden_size2,output_size\n",
    "'''\n",
    "rnn_a_sf2 = RNN_Attn_StatFeat(input_size=vec_size,feat_size=feat_size,\n",
    "                             hidden_size=hidden_size,hidden_size2=hidden_size2,\n",
    "                             output_size=y_train_sn_ro.shape[1]).to(device)\n",
    "optimizer = optim.Adam(rnn_a_sf2.parameters(),lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = DataLoader(TensorDataset(X_train_sn_ro.to(device),sf_train_sn_ro.to(device),y_train_sn_ro.to(device)),batch_size=batch_size)\n",
    "'''\n",
    "train_and_save args: model,filename,\n",
    "                   loss_fn,optimizer,\n",
    "                   loader,\n",
    "                   y_val_nn,y_val,n_epochs=40,sf=False,**kwargs\n",
    "'''\n",
    "rnn_a_sf2 = train_and_save(rnn_a_sf2,'RNN_Attn_sf_v2.pt',\n",
    "                     loss_fn,optimizer,\n",
    "                     loader,y_val_sn_ro_nn.to(device),y_val_sn_ro,sf=True,X_val=X_val_sn_ro.to(device),sf_val=sf_val_sn_ro.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afa562",
   "metadata": {},
   "source": [
    "#### Other Hyperparam-like Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd14c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To test:\n",
    "- 1 more hidden layer for RNN_Attn_StatFeat?\n",
    "'''\n",
    "no_print=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "842bddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Results:\n",
    "- RNN_Attn - Epoch13: val loss=0.45884597301483154, balanced accuracy=0.755593651602055, precision=0.8039308068696814, recall=0.8060344827586207, fscore=0.8028471981210324\n",
    "- RNN_Attn_StatFeat - Epoch29: val loss=0.6968145370483398, balanced accuracy=0.819888056232594, precision=0.8485338182885594, recall=0.8497536945812808, fscore=0.8471742309103825\n",
    "- RNN_Attn_StatFeat with sectionName - Epoch26: val loss=0.6687561273574829, balanced accuracy=0.8488238729835368, precision=0.8824253380976532, recall=0.8811576354679803, fscore=0.879580416187504\n",
    "\n",
    "Observations:\n",
    "- Results (esp for RNN_Attn) are worse with softmax than without\n",
    "\n",
    "Actions taken to address problem of assigning all samples to one class:\n",
    "- Removed outlier samples with extremely high word counts (>100) (worked for Attn. RNN unaffected)\n",
    "- Resampling (tried for RNN; didn't work)\n",
    "- Weighted loss (tried for RNN; didn't work)\n",
    "'''\n",
    "no_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02734d1a",
   "metadata": {},
   "source": [
    "### Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88991897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pytorch lightning, lightning fabric\n",
    "'''\n",
    "no_print=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888b7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
