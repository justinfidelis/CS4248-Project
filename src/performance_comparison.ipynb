{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import load_dataset_split\n",
    "from feature_extractor import FeatureExtractor\n",
    "from log_regression import LogReg\n",
    "from mlp import MLP\n",
    "\n",
    "\n",
    "train_x, train_y, test_x, test_y = load_dataset_split()\n",
    "\n",
    "feature_list = {\"pos_tag\", \"word_vector\", \"glove_embedding\"}\n",
    "vect = \"count\"\n",
    "vect_pca = True\n",
    "vect_filter = True\n",
    "\n",
    "feature_ext = FeatureExtractor(feature_list=feature_list, word_vectorizer=vect, vector_pca=vect_pca, vector_filter=vect_filter)\n",
    "\n",
    "train_feat = feature_ext.extract_features(train_x, train=True)\n",
    "test_feat = feature_ext.extract_features(test_x, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogReg , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7963460505104782\n",
      "F1 Score:  0.7673413870701756\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogReg()\n",
    "\n",
    "model_lr.train(train_feat, train_y)\n",
    "lr_test_pred = model_lr.predict(test_feat)\n",
    "\n",
    "print(f\"Model: LogReg\", f\", Features: {feature_list}\")\n",
    "if \"word_vector\" in feature_list:\n",
    "    print(f\"Vectorizer: {vect}\") \n",
    "    print(f\"Vector PCA: {vect_pca}\")\n",
    "    print(f\"Vector Remove Stop Words / Numbers: {vect_filter}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, lr_test_pred))\n",
    "print(\"F1 Score: \", f1_score(test_y, lr_test_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 212\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Size: {len(train_feat.to_numpy()[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "59/59 [==============================] - 0s 893us/step\n",
      "Epoch: 0\n",
      "F1 Score:  0.7299658256529816\n",
      "59/59 [==============================] - 0s 881us/step\n",
      "Epoch: 5\n",
      "F1 Score:  0.7458682612140918\n",
      "59/59 [==============================] - 0s 912us/step\n",
      "Epoch: 10\n",
      "F1 Score:  0.7424956842117177\n",
      "59/59 [==============================] - 0s 942us/step\n",
      "Epoch: 15\n",
      "F1 Score:  0.7587300762374732\n",
      "59/59 [==============================] - 0s 979us/step\n",
      "Epoch: 20\n",
      "F1 Score:  0.759203498040657\n",
      "59/59 [==============================] - 1s 16ms/step\n",
      "Epoch: 25\n",
      "F1 Score:  0.7531400885816361\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 30\n",
      "F1 Score:  0.7541852587050327\n",
      "59/59 [==============================] - 0s 941us/step\n",
      "Epoch: 35\n",
      "F1 Score:  0.7625892847957448\n",
      "Model: MLP , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7931219774314885\n",
      "F1 Score:  0.7625892847957448\n",
      "Iteration 1\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 0\n",
      "F1 Score:  0.7332101988115305\n",
      "59/59 [==============================] - 0s 892us/step\n",
      "Epoch: 5\n",
      "F1 Score:  0.7483907372918209\n",
      "59/59 [==============================] - 0s 948us/step\n",
      "Epoch: 10\n",
      "F1 Score:  0.7512590695689286\n",
      "59/59 [==============================] - 0s 954us/step\n",
      "Epoch: 15\n",
      "F1 Score:  0.7610716846370528\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 20\n",
      "F1 Score:  0.7501299904692367\n",
      "59/59 [==============================] - 0s 912us/step\n",
      "Epoch: 25\n",
      "F1 Score:  0.7463748150503826\n",
      "59/59 [==============================] - 0s 927us/step\n",
      "Epoch: 30\n",
      "F1 Score:  0.754796623986335\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 35\n",
      "F1 Score:  0.7408953535199588\n",
      "Model: MLP , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7770016120365395\n",
      "F1 Score:  0.7408953535199588\n",
      "Iteration 2\n",
      "59/59 [==============================] - 0s 913us/step\n",
      "Epoch: 0\n",
      "F1 Score:  0.7186158763207965\n",
      "59/59 [==============================] - 0s 936us/step\n",
      "Epoch: 5\n",
      "F1 Score:  0.7245112353144733\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 10\n",
      "F1 Score:  0.7391693847387805\n",
      "59/59 [==============================] - 0s 967us/step\n",
      "Epoch: 15\n",
      "F1 Score:  0.7618860059111632\n",
      "59/59 [==============================] - 0s 896us/step\n",
      "Epoch: 20\n",
      "F1 Score:  0.7620843346466747\n",
      "59/59 [==============================] - 0s 890us/step\n",
      "Epoch: 25\n",
      "F1 Score:  0.7561738894477683\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 30\n",
      "F1 Score:  0.7621404373398039\n",
      "59/59 [==============================] - 0s 995us/step\n",
      "Epoch: 35\n",
      "F1 Score:  0.7661624927543453\n",
      "Model: MLP , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7952713594841483\n",
      "F1 Score:  0.7661624927543453\n",
      "Iteration 3\n",
      "59/59 [==============================] - 0s 923us/step\n",
      "Epoch: 0\n",
      "F1 Score:  0.7196098963841132\n",
      "59/59 [==============================] - 0s 947us/step\n",
      "Epoch: 5\n",
      "F1 Score:  0.7507579949118881\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 10\n",
      "F1 Score:  0.7565543441208283\n",
      "59/59 [==============================] - 0s 917us/step\n",
      "Epoch: 15\n",
      "F1 Score:  0.7591956965135203\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 20\n",
      "F1 Score:  0.7630338293999968\n",
      "59/59 [==============================] - 0s 931us/step\n",
      "Epoch: 25\n",
      "F1 Score:  0.7644613629513103\n",
      "59/59 [==============================] - 0s 980us/step\n",
      "Epoch: 30\n",
      "F1 Score:  0.7481777484577626\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 35\n",
      "F1 Score:  0.764013183497239\n",
      "Model: MLP , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7952713594841483\n",
      "F1 Score:  0.764013183497239\n",
      "Iteration 4\n",
      "59/59 [==============================] - 0s 899us/step\n",
      "Epoch: 0\n",
      "F1 Score:  0.709951246915609\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "Epoch: 5\n",
      "F1 Score:  0.7526524422731219\n",
      "59/59 [==============================] - 0s 901us/step\n",
      "Epoch: 10\n",
      "F1 Score:  0.7548713124403733\n",
      "59/59 [==============================] - 0s 933us/step\n",
      "Epoch: 15\n",
      "F1 Score:  0.7597218590275384\n",
      "59/59 [==============================] - 0s 928us/step\n",
      "Epoch: 20\n",
      "F1 Score:  0.7614204283828631\n",
      "59/59 [==============================] - 0s 993us/step\n",
      "Epoch: 25\n",
      "F1 Score:  0.7560192629774148\n",
      "59/59 [==============================] - 0s 943us/step\n",
      "Epoch: 30\n",
      "F1 Score:  0.7528152202286943\n",
      "59/59 [==============================] - 0s 848us/step\n",
      "Epoch: 35\n",
      "F1 Score:  0.7367718246329039\n",
      "Model: MLP , Features: {'word_vector', 'pos_tag', 'glove_embedding'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Vector Remove Stop Words / Numbers: True\n",
      "Accuracy:  0.7748522299838796\n",
      "F1 Score:  0.7367718246329039\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    score = []\n",
    "    model_mlp = MLP([len(train_feat.to_numpy()[0])])\n",
    "\n",
    "    print(f\"Iteration {i}\")\n",
    "    for j in range(8):\n",
    "        model_mlp.train(train_feat, train_y, epochs=5, print=0)\n",
    "        mlp_test_pred = model_mlp.predict(test_feat)\n",
    "        f1 = f1_score(test_y, mlp_test_pred, average=\"macro\")\n",
    "        print(f\"Epoch: {j * 5}\")\n",
    "        print(\"F1 Score: \", f1)\n",
    "        score.append(f1)\n",
    "\n",
    "\n",
    "    print(f\"Model: MLP\", f\", Features: {feature_list}\")\n",
    "    if \"word_vector\" in feature_list:\n",
    "        print(f\"Vectorizer: {vect}\") \n",
    "        print(f\"Vector PCA: {vect_pca}\")\n",
    "        print(f\"Vector Remove Stop Words / Numbers: {vect_filter}\")\n",
    "    print(\"Accuracy: \", accuracy_score(test_y, mlp_test_pred))\n",
    "    print(\"F1 Score: \", f1)\n",
    "\n",
    "    f1_scores.append(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222706088170062\n",
      "0.7444361342010792\n",
      "0.7488699590161256\n",
      "0.7601210644653495\n",
      "0.7591744161878856\n",
      "0.7552338838017023\n",
      "0.7544230577435257\n",
      "0.7540864278400383\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    s = 0\n",
    "    for j in range(5):\n",
    "        s += f1_scores[j][i]\n",
    "    print(s / 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
