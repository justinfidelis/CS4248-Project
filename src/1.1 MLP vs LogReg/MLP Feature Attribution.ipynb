{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Feature Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_extractor import FeatureExtractor\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from utils import load_dataset_split\n",
    "from mlp_torch import MLP, CitationDataset\n",
    "\n",
    "def idx_to_label(y):\n",
    "    mapping = [\"background\", \"method\", \"result\"]\n",
    "    out = []\n",
    "    for i in y:\n",
    "        out.append(mapping[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_dataset_split()\n",
    "\n",
    "feature_list = {\"word_vector\"}\n",
    "vect = \"count\"\n",
    "vect_pca = True\n",
    "\n",
    "feat_ext = FeatureExtractor(feature_list=feature_list, word_vectorizer=vect, vector_pca=False, vector_filter=True)\n",
    "train_feat = feat_ext.extract_features(train_x, train=True).values\n",
    "test_feat = feat_ext.extract_features(test_x).values\n",
    "\n",
    "train_data = CitationDataset(train_feat, train_y.values)\n",
    "test_data = CitationDataset(test_feat, test_y.values)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27424\n"
     ]
    }
   ],
   "source": [
    "print(len(train_feat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 30 Loss: 0.737544059753418\n",
      "Epoch: 1 / 30 Loss: 0.6256468892097473\n",
      "Epoch: 2 / 30 Loss: 0.11711911112070084\n",
      "Epoch: 3 / 30 Loss: 0.048118870705366135\n",
      "Epoch: 4 / 30 Loss: 0.005014120135456324\n",
      "Epoch: 5 / 30 Loss: 0.0019885061774402857\n",
      "Epoch: 6 / 30 Loss: 0.00027434463845565915\n",
      "Epoch: 7 / 30 Loss: 0.00011717282905010507\n",
      "Epoch: 8 / 30 Loss: 0.0004549185687210411\n",
      "Epoch: 9 / 30 Loss: 0.00017286477668676525\n",
      "Epoch: 10 / 30 Loss: 4.721865479950793e-05\n",
      "Epoch: 11 / 30 Loss: 0.0004317023849580437\n",
      "Epoch: 12 / 30 Loss: 0.17438974976539612\n",
      "Epoch: 13 / 30 Loss: 0.00013715215027332306\n",
      "Epoch: 14 / 30 Loss: 0.00010179907258134335\n",
      "Epoch: 15 / 30 Loss: 1.0813814697030466e-05\n",
      "Epoch: 16 / 30 Loss: 0.0012265030527487397\n",
      "Epoch: 17 / 30 Loss: 6.302192196017131e-05\n",
      "Epoch: 18 / 30 Loss: 5.658420195686631e-05\n",
      "Epoch: 19 / 30 Loss: 3.116462266916642e-06\n",
      "Epoch: 20 / 30 Loss: 3.547002052073367e-05\n",
      "Epoch: 21 / 30 Loss: 8.208321560232434e-06\n",
      "Epoch: 22 / 30 Loss: 9.29822363104904e-06\n",
      "Epoch: 23 / 30 Loss: 0.000542868860065937\n",
      "Epoch: 24 / 30 Loss: 7.053135050227866e-05\n",
      "Epoch: 25 / 30 Loss: 0.000736178015358746\n",
      "Epoch: 26 / 30 Loss: 0.00015855384117458016\n",
      "Epoch: 27 / 30 Loss: 0.00012505502672865987\n",
      "Epoch: 28 / 30 Loss: 0.0009612442227080464\n",
      "Epoch: 29 / 30 Loss: 0.0007206448353827\n",
      "Model: MLP_torch , Features: {'word_vector'}\n",
      "Vectorizer: count\n",
      "Vector PCA: True\n",
      "Accuracy:  0.7248790972595379\n",
      "F1 Score:  0.7004700831405525\n"
     ]
    }
   ],
   "source": [
    "model = MLP(len(train_feat[0]))\n",
    "model.cuda()\n",
    "\n",
    "model.train(train_dataloader)\n",
    "test_pred = idx_to_label(model.predict(test_dataloader))\n",
    "\n",
    "print(f\"Model: MLP_torch\", f\", Features: {feature_list}\")\n",
    "if \"word_vector\" in feature_list:\n",
    "    print(f\"Vectorizer: {vect}\") \n",
    "    print(f\"Vector PCA: {vect_pca}\")\n",
    "print(\"Accuracy: \", accuracy_score(test_y, test_pred))\n",
    "print(\"F1 Score: \", f1_score(test_y, test_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "input_sentence = \"Our findings agree with recent work [69,70] where continual organic enrichment from farming processes resulted in increased macrofaunal abundances despite expectations of negative impacts from this contamination.\"\n",
    "input_feat = feat_ext.extract_features([input_sentence]).values\n",
    "\n",
    "ig = IntegratedGradients(model)\n",
    "input = torch.tensor(input_feat, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "all_attributions = []\n",
    "\n",
    "for class_idx in range(3):\n",
    "    attributions, approx_error = ig.attribute(input, target=class_idx, return_convergence_delta=True, internal_batch_size=16)\n",
    "\n",
    "    all_attributions.append(attributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., -0.,  ..., 0., 0., 0.]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>), tensor([[-0., 0., 0.,  ..., -0., -0., -0.]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>), tensor([[0., -0., 0.,  ..., -0., 0., -0.]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(all_attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background\n",
      "impacts: 1.510992095572858\n",
      "organic: 0.6065488973995976\n",
      "processes: 0.5074216984608848\n",
      "contamination: 0.49124341475879724\n",
      "work: 0.4700559090309714\n",
      "farming: 0.4235120323462682\n",
      "increased: 0.30183356369221287\n",
      "negative: 0.23394303795982874\n",
      "abundances: 0.1537517331778544\n",
      "enrichment: 0.11386483945215153\n",
      "aa: 0.0\n",
      "aachen: 0.0\n",
      "aactg: -0.0\n",
      "aadahl: 0.0\n",
      "aaednv: 0.0\n",
      "aag: 0.0\n",
      "aagaard: -0.0\n",
      "aal: -0.0\n",
      "aalto: 0.0\n",
      "aamm: -0.0\n",
      "\n",
      "method\n",
      "expectations: 0.9323014375137118\n",
      "negative: 0.16624281165705737\n",
      "farming: 0.09265758557394345\n",
      "enrichment: 0.06247529718311356\n",
      "aa: -0.0\n",
      "aachen: 0.0\n",
      "aactg: 0.0\n",
      "aadahl: -0.0\n",
      "aaednv: -0.0\n",
      "aag: -0.0\n",
      "aagaard: 0.0\n",
      "aal: 0.0\n",
      "aalto: -0.0\n",
      "aamm: 0.0\n",
      "aamodt: -0.0\n",
      "aanonsen: -0.0\n",
      "aao: -0.0\n",
      "aaos: -0.0\n",
      "aap: -0.0\n",
      "aaps: -0.0\n",
      "\n",
      "results\n",
      "findings: 2.4839210235223477\n",
      "agree: 1.5080942692521186\n",
      "despite: 1.447583054018094\n",
      "resulted: 1.2505068467132894\n",
      "recent: 0.3690873031705178\n",
      "abundances: 0.21612012696152066\n",
      "work: 0.07467093306865327\n",
      "contamination: 0.07435091744049478\n",
      "processes: 0.06579236976907579\n",
      "aa: 0.0\n",
      "aachen: -0.0\n",
      "aactg: 0.0\n",
      "aadahl: 0.0\n",
      "aaednv: -0.0\n",
      "aag: -0.0\n",
      "aagaard: 0.0\n",
      "aal: 0.0\n",
      "aalto: -0.0\n",
      "aamm: -0.0\n",
      "aamodt: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = feat_ext.vectorizer.vocabulary_\n",
    "\n",
    "word_list = [w for w, _ in sorted(vocab.items(), key=lambda x: x[1])]\n",
    "\n",
    "mean_val = torch.mean(torch.stack([torch.mean(i, 0) for i in all_attributions]), dim=0)\n",
    "\n",
    "labels = [\"background\", \"method\", \"results\"]\n",
    "\n",
    "for label, attributions in zip(labels, all_attributions):\n",
    "    sorted_words = [(word, weight) for word, weight in sorted(zip(word_list, attributions[0]), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "    print(label)\n",
    "    for word, weight in sorted_words[:20]:\n",
    "        print(f\"{word}: {weight}\")\n",
    "    print(\"\")\n",
    "\n",
    "# for label, attributions in zip(labels, all_attributions):\n",
    "#     mean_att = torch.mean(attributions, 0) - mean_val\n",
    "#     weights = [i.item() for i in mean_att]\n",
    "\n",
    "#     sorted_words = [(word, weight) for word, weight in sorted(zip(word_list, weights), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "#     print(label)\n",
    "#     for word, weight in sorted_words[:20]:\n",
    "#         print(f\"{word}: {weight}\")\n",
    "#     print(\"\")\n",
    "\n",
    "#     with open(f\"../results/mlp_stopword_{label}.txt\", \"a\") as f:\n",
    "#         for word, weight in sorted_words:\n",
    "#             f.write(f\"{word}: {weight}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
